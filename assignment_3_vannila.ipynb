{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T15:30:15.523412Z",
     "iopub.status.busy": "2025-05-19T15:30:15.523193Z",
     "iopub.status.idle": "2025-05-19T15:30:25.431542Z",
     "shell.execute_reply": "2025-05-19T15:30:25.430976Z",
     "shell.execute_reply.started": "2025-05-19T15:30:15.523395Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mda24m016\u001b[0m (\u001b[33mda24m016-indian-institute-of-technology-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "user_secrets = UserSecretsClient()\n",
    "\n",
    "my_secret = user_secrets.get_secret(\"wandb_api\") \n",
    "\n",
    "wandb.login(key=my_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T15:30:25.435384Z",
     "iopub.status.busy": "2025-05-19T15:30:25.435214Z",
     "iopub.status.idle": "2025-05-19T15:30:29.994652Z",
     "shell.execute_reply": "2025-05-19T15:30:29.994127Z",
     "shell.execute_reply.started": "2025-05-19T15:30:25.435369Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wandb\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ---- Dataset Definition with special tokens ----\n",
    "class DakshinaTSVDataset(Dataset):\n",
    "    def __init__(self, tsv_file, src_vocab=None, tgt_vocab=None, max_len=64, build_vocab=False):\n",
    "        df = pd.read_csv(tsv_file, sep='\\t', header=None,\n",
    "                         names=['native', 'roman', 'freq'], usecols=[0, 1], dtype=str)\n",
    "        # Fix the pandas warning by using a copy\n",
    "        df = df.copy()\n",
    "        df['native'] = df['native'].fillna('')\n",
    "        df['roman'] = df['roman'].fillna('')\n",
    "        self.pairs = list(zip(df['roman'], df['native']))\n",
    "        print(f\"Loaded {len(self.pairs)} examples from {tsv_file}\")\n",
    "        \n",
    "        # Print a few examples\n",
    "        if len(self.pairs) > 0:\n",
    "            print(\"Sample examples:\")\n",
    "            for i in range(min(3, len(self.pairs))):\n",
    "                print(f\"  Roman: '{self.pairs[i][0]}', Native: '{self.pairs[i][1]}'\")\n",
    "                \n",
    "        self.max_len = max_len\n",
    "        \n",
    "        if build_vocab:\n",
    "            self.src_vocab = {'<pad>': 0, '<unk>': 1, '<eos>': 2, '<sos>': 3}\n",
    "            self.tgt_vocab = {'<pad>': 0, '<unk>': 1, '<eos>': 2, '<sos>': 3}\n",
    "            self._build_vocab()\n",
    "        else:\n",
    "            self.src_vocab, self.tgt_vocab = src_vocab, tgt_vocab\n",
    "            # Ensure special tokens exist\n",
    "            for v in ('<eos>', '<sos>'):\n",
    "                if v not in self.src_vocab: self.src_vocab[v] = len(self.src_vocab)\n",
    "                if v not in self.tgt_vocab: self.tgt_vocab[v] = len(self.tgt_vocab)\n",
    "\n",
    "    def _build_vocab(self):\n",
    "        for src, tgt in self.pairs:\n",
    "            for ch in src:\n",
    "                if ch not in self.src_vocab: self.src_vocab[ch] = len(self.src_vocab)\n",
    "            for ch in tgt:\n",
    "                if ch not in self.tgt_vocab: self.tgt_vocab[ch] = len(self.tgt_vocab)\n",
    "        print(f\"Vocab sizes -> src: {len(self.src_vocab)}, tgt: {len(self.tgt_vocab)}\")\n",
    "\n",
    "    def __len__(self): return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src, tgt = self.pairs[idx]\n",
    "        \n",
    "        # Add <sos> and <eos> tokens\n",
    "        src_idxs = [self.src_vocab['<sos>']] + [self.src_vocab.get(ch, self.src_vocab['<unk>']) for ch in src] + [self.src_vocab['<eos>']]\n",
    "        tgt_idxs = [self.tgt_vocab['<sos>']] + [self.tgt_vocab.get(ch, self.tgt_vocab['<unk>']) for ch in tgt] + [self.tgt_vocab['<eos>']]\n",
    "        \n",
    "        # Pad sequences\n",
    "        pad_src = [self.src_vocab['<pad>']] * max(0, self.max_len - len(src_idxs))\n",
    "        pad_tgt = [self.tgt_vocab['<pad>']] * max(0, self.max_len - len(tgt_idxs))\n",
    "        \n",
    "        # Truncate if necessary and convert to tensor\n",
    "        src_tensor = torch.tensor((src_idxs + pad_src)[:self.max_len], dtype=torch.long)\n",
    "        tgt_tensor = torch.tensor((tgt_idxs + pad_tgt)[:self.max_len], dtype=torch.long)\n",
    "        \n",
    "        return src_tensor, tgt_tensor\n",
    "\n",
    "# ---- Encoder with bidirectional support ----\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, dropout=0, bidirectional=True, cell_type='lstm'):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.bidirectional = bidirectional\n",
    "        self.cell_type = cell_type.lower()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, embedding_size, padding_idx=0)\n",
    "        \n",
    "        if self.cell_type == 'lstm':\n",
    "            self.rnn = nn.LSTM(\n",
    "                embedding_size, \n",
    "                hidden_size, \n",
    "                num_layers=num_layers, \n",
    "                dropout=dropout if num_layers > 1 else 0,\n",
    "                bidirectional=bidirectional,\n",
    "                batch_first=True\n",
    "            )\n",
    "        elif self.cell_type == 'gru':\n",
    "            self.rnn = nn.GRU(\n",
    "                embedding_size, \n",
    "                hidden_size, \n",
    "                num_layers=num_layers, \n",
    "                dropout=dropout if num_layers > 1 else 0,\n",
    "                bidirectional=bidirectional,\n",
    "                batch_first=True\n",
    "            )\n",
    "        else:  # rnn\n",
    "            self.rnn = nn.RNN(\n",
    "                embedding_size, \n",
    "                hidden_size, \n",
    "                num_layers=num_layers, \n",
    "                dropout=dropout if num_layers > 1 else 0,\n",
    "                bidirectional=bidirectional,\n",
    "                batch_first=True\n",
    "            )\n",
    "            \n",
    "        # Initialize weights\n",
    "        for name, param in self.named_parameters():\n",
    "            if 'weight' in name and 'embedding' not in name:\n",
    "                nn.init.xavier_uniform_(param)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        # x: [batch_size, seq_len]\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        # Create mask for attention\n",
    "        mask = (x != 0).float()  # 0 is <pad>\n",
    "        \n",
    "        # Embedding\n",
    "        embedded = self.embedding(x)  # [batch_size, seq_len, embedding_size]\n",
    "        \n",
    "        # Pass through RNN\n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "        \n",
    "        # Process hidden state based on RNN type\n",
    "        if self.cell_type == 'lstm':\n",
    "            hidden_state, cell_state = hidden\n",
    "            \n",
    "            if self.bidirectional:\n",
    "                # Reshape hidden from [num_layers*2, batch_size, hidden_size]\n",
    "                # to [num_layers, 2, batch_size, hidden_size]\n",
    "                hidden_state = hidden_state.view(self.num_layers, 2, batch_size, self.hidden_size)\n",
    "                cell_state = cell_state.view(self.num_layers, 2, batch_size, self.hidden_size)\n",
    "                \n",
    "                # Concatenate bidirectional states\n",
    "                hidden_state = torch.cat([hidden_state[:, 0], hidden_state[:, 1]], dim=2)\n",
    "                cell_state = torch.cat([cell_state[:, 0], cell_state[:, 1]], dim=2)\n",
    "                \n",
    "                # Final hidden state is now [num_layers, batch_size, hidden_size*2]\n",
    "                hidden = (hidden_state, cell_state)\n",
    "            \n",
    "        else:  # GRU or RNN\n",
    "            if self.bidirectional:\n",
    "                # Reshape hidden from [num_layers*2, batch_size, hidden_size]\n",
    "                # to [num_layers, 2, batch_size, hidden_size]\n",
    "                hidden = hidden.view(self.num_layers, 2, batch_size, self.hidden_size)\n",
    "                \n",
    "                # Concatenate bidirectional states\n",
    "                hidden = torch.cat([hidden[:, 0], hidden[:, 1]], dim=2)\n",
    "                \n",
    "                # Final hidden state is now [num_layers, batch_size, hidden_size*2]\n",
    "        \n",
    "        # For bidirectional, output is [batch_size, seq_len, hidden_size*2]\n",
    "        return outputs, hidden, mask\n",
    "\n",
    "# ---- Attention Mechanism ----\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, enc_hidden_size, dec_hidden_size):\n",
    "        super().__init__()\n",
    "        # Create a linear layer to convert the concatenated hidden states to attention scores\n",
    "        self.energy = nn.Linear(enc_hidden_size + dec_hidden_size, dec_hidden_size)\n",
    "        self.v = nn.Linear(dec_hidden_size, 1, bias=False)\n",
    "        \n",
    "    def forward(self, hidden, encoder_outputs, mask):\n",
    "        # hidden: [batch_size, dec_hidden_size]\n",
    "        # encoder_outputs: [batch_size, src_len, enc_hidden_size]\n",
    "        # mask: [batch_size, src_len]\n",
    "        \n",
    "        batch_size = encoder_outputs.shape[0]\n",
    "        src_len = encoder_outputs.shape[1]\n",
    "        \n",
    "        # Repeat decoder hidden state src_len times\n",
    "        # [batch_size, dec_hidden_size] -> [batch_size, src_len, dec_hidden_size]\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "        \n",
    "        # Create energy by concatenating encoder outputs and decoder hidden\n",
    "        # [batch_size, src_len, enc_hidden_size + dec_hidden_size]\n",
    "        energy = torch.cat((hidden, encoder_outputs), dim=2)\n",
    "        \n",
    "        # Apply attention layer\n",
    "        # [batch_size, src_len, dec_hidden_size]\n",
    "        energy = torch.tanh(self.energy(energy))\n",
    "        \n",
    "        # Get attention scores\n",
    "        # [batch_size, src_len, 1]\n",
    "        attention = self.v(energy)\n",
    "        \n",
    "        # [batch_size, src_len]\n",
    "        attention = attention.squeeze(2)\n",
    "        \n",
    "        # Mask out padding positions\n",
    "        attention = attention.masked_fill(mask == 0, -1e10)\n",
    "        \n",
    "        # Apply softmax to get probabilities\n",
    "        # [batch_size, src_len]\n",
    "        return F.softmax(attention, dim=1)\n",
    "\n",
    "# ---- Decoder with attention and teacher forcing ----\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_size, embedding_size, enc_hidden_size, dec_hidden_size, \n",
    "                 num_layers, dropout=0, cell_type='lstm'):\n",
    "        super().__init__()\n",
    "        self.output_size = output_size\n",
    "        self.dec_hidden_size = dec_hidden_size\n",
    "        self.enc_hidden_size = enc_hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.cell_type = cell_type.lower()\n",
    "        \n",
    "        # Initialize embedding layer\n",
    "        self.embedding = nn.Embedding(output_size, embedding_size, padding_idx=0)\n",
    "        \n",
    "        # Initialize attention mechanism\n",
    "        self.attention = Attention(enc_hidden_size, dec_hidden_size)\n",
    "        \n",
    "        # Context vector + embedding size as input to RNN\n",
    "        rnn_input_size = embedding_size + enc_hidden_size\n",
    "        \n",
    "        # Initialize RNN based on cell type\n",
    "        if self.cell_type == 'lstm':\n",
    "            self.rnn = nn.LSTM(\n",
    "                rnn_input_size, \n",
    "                dec_hidden_size, \n",
    "                num_layers=num_layers, \n",
    "                dropout=dropout if num_layers > 1 else 0,\n",
    "                batch_first=True\n",
    "            )\n",
    "        elif self.cell_type == 'gru':\n",
    "            self.rnn = nn.GRU(\n",
    "                rnn_input_size, \n",
    "                dec_hidden_size, \n",
    "                num_layers=num_layers, \n",
    "                dropout=dropout if num_layers > 1 else 0,\n",
    "                batch_first=True\n",
    "            )\n",
    "        else:  # rnn\n",
    "            self.rnn = nn.RNN(\n",
    "                rnn_input_size, \n",
    "                dec_hidden_size, \n",
    "                num_layers=num_layers, \n",
    "                dropout=dropout if num_layers > 1 else 0,\n",
    "                batch_first=True\n",
    "            )\n",
    "        \n",
    "        # Final output layer that combines decoder output, context and embedding\n",
    "        self.fc_out = nn.Linear(dec_hidden_size + enc_hidden_size + embedding_size, output_size)\n",
    "        \n",
    "        # Initialize weights using Xavier initialization\n",
    "        for name, param in self.named_parameters():\n",
    "            if 'weight' in name and 'embedding' not in name:\n",
    "                nn.init.xavier_uniform_(param)\n",
    "                \n",
    "    def forward(self, input, hidden, encoder_outputs, mask):\n",
    "        # input: [batch_size]\n",
    "        # hidden: [num_layers, batch_size, dec_hidden_size] or tuple for LSTM\n",
    "        # encoder_outputs: [batch_size, src_len, enc_hidden_size]\n",
    "        # mask: [batch_size, src_len]\n",
    "        \n",
    "        # Embed input token\n",
    "        # [batch_size] -> [batch_size, 1, embedding_size]\n",
    "        embedded = self.embedding(input).unsqueeze(1)\n",
    "        \n",
    "        # Get attention weights\n",
    "        # [batch_size, src_len]\n",
    "        if self.cell_type == 'lstm':\n",
    "            h_for_attn = hidden[0][-1]  # use last layer's hidden state\n",
    "        else:\n",
    "            h_for_attn = hidden[-1]  # use last layer's hidden state\n",
    "            \n",
    "        attn_weights = self.attention(h_for_attn, encoder_outputs, mask)\n",
    "        \n",
    "        # Create context vector by weighting encoder outputs with attention\n",
    "        # [batch_size, 1, src_len] * [batch_size, src_len, enc_hidden_size]\n",
    "        # -> [batch_size, 1, enc_hidden_size]\n",
    "        context = torch.bmm(attn_weights.unsqueeze(1), encoder_outputs)\n",
    "        \n",
    "        # Combine embedded token and context vector\n",
    "        # [batch_size, 1, embedding_size + enc_hidden_size]\n",
    "        rnn_input = torch.cat((embedded, context), dim=2)\n",
    "        \n",
    "        # Pass through RNN\n",
    "        # output: [batch_size, 1, dec_hidden_size]\n",
    "        # hidden: [num_layers, batch_size, dec_hidden_size] or tuple for LSTM\n",
    "        output, hidden = self.rnn(rnn_input, hidden)\n",
    "        \n",
    "        # Combine output, context and embedding for final prediction\n",
    "        # [batch_size, 1, dec_hidden_size + enc_hidden_size + embedding_size]\n",
    "        output = torch.cat((output, context, embedded), dim=2)\n",
    "        \n",
    "        # Remove sequence dimension\n",
    "        # [batch_size, dec_hidden_size + enc_hidden_size + embedding_size]\n",
    "        output = output.squeeze(1)\n",
    "        \n",
    "        # Pass through final linear layer\n",
    "        # [batch_size, output_size]\n",
    "        prediction = self.fc_out(output)\n",
    "        \n",
    "        return prediction, hidden, attn_weights\n",
    "\n",
    "# ---- Complete Seq2Seq Model with Teacher Forcing ----\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device, teacher_forcing_ratio=0.7):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
    "        \n",
    "    def forward(self, src, tgt):\n",
    "        # src: [batch_size, src_len]\n",
    "        # tgt: [batch_size, tgt_len]\n",
    "        \n",
    "        batch_size = src.shape[0]\n",
    "        tgt_len = tgt.shape[1]\n",
    "        tgt_vocab_size = self.decoder.output_size\n",
    "        \n",
    "        # Tensor to store outputs\n",
    "        outputs = torch.zeros(batch_size, tgt_len-1, tgt_vocab_size).to(self.device)\n",
    "        \n",
    "        # Encode source\n",
    "        encoder_outputs, hidden, mask = self.encoder(src)\n",
    "        \n",
    "        # First input to decoder is the <sos> token (already embedded in tgt)\n",
    "        input = tgt[:, 0]\n",
    "        \n",
    "        # Teacher forcing ratio determines how often to use true target as input\n",
    "        use_teacher_forcing = random.random() < self.teacher_forcing_ratio\n",
    "        \n",
    "        # Decode one token at a time\n",
    "        for t in range(1, tgt_len):\n",
    "            # Get output from decoder\n",
    "            output, hidden, _ = self.decoder(input, hidden, encoder_outputs, mask)\n",
    "            \n",
    "            # Store output\n",
    "            outputs[:, t-1] = output\n",
    "            \n",
    "            # Next input is either true target (teacher forcing) or predicted token\n",
    "            if use_teacher_forcing:\n",
    "                input = tgt[:, t]\n",
    "            else:\n",
    "                # Get highest scoring token\n",
    "                input = output.argmax(1)\n",
    "                \n",
    "        return outputs\n",
    "    \n",
    "    # For inference (no teacher forcing)\n",
    "    def decode(self, src, max_len=100):\n",
    "        # src: [batch_size, src_len]\n",
    "        \n",
    "        batch_size = src.shape[0]\n",
    "        \n",
    "        # Encode source\n",
    "        encoder_outputs, hidden, mask = self.encoder(src)\n",
    "        \n",
    "        # First input is <sos> token\n",
    "        input = torch.ones(batch_size, dtype=torch.long).to(self.device) * 3  # <sos> = 3\n",
    "        \n",
    "        # Track generated tokens\n",
    "        outputs = [input]\n",
    "        attentions = []\n",
    "        \n",
    "        # Track if sequence has ended\n",
    "        ended = torch.zeros(batch_size, dtype=torch.bool).to(self.device)\n",
    "        \n",
    "        # Decode until max length or all sequences end\n",
    "        for t in range(1, max_len):\n",
    "            # Get output from decoder\n",
    "            output, hidden, attn = self.decoder(input, hidden, encoder_outputs, mask)\n",
    "            \n",
    "            # Get next token\n",
    "            input = output.argmax(1)\n",
    "            \n",
    "            # Store output\n",
    "            outputs.append(input)\n",
    "            attentions.append(attn)\n",
    "            \n",
    "            # Check if all sequences have ended\n",
    "            ended = ended | (input == 2)  # 2 is <eos>\n",
    "            if ended.all():\n",
    "                break\n",
    "                \n",
    "        # Convert list of tensors to single tensor\n",
    "        outputs = torch.stack(outputs, dim=1)  # [batch_size, seq_len]\n",
    "        attentions = torch.stack(attentions, dim=1)  # [batch_size, seq_len-1, src_len]\n",
    "        \n",
    "        return outputs, attentions\n",
    "\n",
    "# ---- Metrics & Utils ----\n",
    "def compute_exact_match_accuracy(preds, targets, tgt_vocab):\n",
    "    \"\"\"Compute exact match accuracy between predictions and targets\"\"\"\n",
    "    batch_size = preds.size(0)\n",
    "    correct = 0\n",
    "    \n",
    "    # Convert ids to strings\n",
    "    id_to_char = {v: k for k, v in tgt_vocab.items() if k not in ['<pad>', '<sos>', '<eos>', '<unk>']}\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        # Extract character sequences (removing special tokens)\n",
    "        pred_seq = ''.join([id_to_char.get(idx.item(), '') for idx in preds[i, 1:] \n",
    "                            if idx.item() not in [0, 1, 2, 3]])  # Skip <pad>, <unk>, <eos>, <sos>\n",
    "        \n",
    "        # For target, skip first token (<sos>) and stop at <eos> or <pad>\n",
    "        tgt_seq = ''\n",
    "        for idx in targets[i, 1:]:  # Skip first token\n",
    "            token_id = idx.item()\n",
    "            if token_id in [0, 2]:  # <pad> or <eos>\n",
    "                break\n",
    "            if token_id not in [1, 3]:  # Skip <unk> and <sos>\n",
    "                tgt_seq += id_to_char.get(token_id, '')\n",
    "        \n",
    "        # Check for exact match\n",
    "        if pred_seq == tgt_seq:\n",
    "            correct += 1\n",
    "    \n",
    "    return correct / batch_size\n",
    "\n",
    "def compute_char_accuracy(logits, targets):\n",
    "    \"\"\"Compute character-level accuracy between logits and targets\"\"\"\n",
    "    preds = logits.argmax(dim=-1)\n",
    "    mask = (targets != 0)  # Ignore padding\n",
    "    correct = ((preds == targets) & mask).sum().item()\n",
    "    total = mask.sum().item()\n",
    "    return correct / total if total > 0 else 0\n",
    "\n",
    "# ---- Training & Evaluation Functions ----\n",
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    epoch_char_acc = 0\n",
    "    epoch_exact_match_acc = 0\n",
    "    total_batches = 0\n",
    "    \n",
    "    for src, tgt in tqdm(dataloader, desc=\"Training\"):\n",
    "        batch_size = src.size(0)\n",
    "        src, tgt = src.to(device), tgt.to(device)\n",
    "        \n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(src, tgt)\n",
    "        \n",
    "        # Flatten output and target tensors for loss calculation\n",
    "        # Ignore the first token in target (<sos>)\n",
    "        output_flat = output.reshape(-1, output.shape[-1])\n",
    "        target_flat = tgt[:, 1:].reshape(-1)  # Shift right to predict next token\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(output_flat, target_flat)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Clip gradients to prevent exploding gradients\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        char_acc = compute_char_accuracy(output, tgt[:, 1:])\n",
    "        \n",
    "        # Decode for exact match accuracy\n",
    "        with torch.no_grad():\n",
    "            predictions, _ = model.decode(src)\n",
    "            exact_match_acc = compute_exact_match_accuracy(predictions, tgt, dataloader.dataset.tgt_vocab)\n",
    "        \n",
    "        # Accumulate metrics\n",
    "        epoch_loss += loss.item() * batch_size\n",
    "        epoch_char_acc += char_acc * batch_size\n",
    "        epoch_exact_match_acc += exact_match_acc * batch_size\n",
    "        total_batches += batch_size\n",
    "    \n",
    "    # Return average metrics\n",
    "    return {\n",
    "        'loss': epoch_loss / total_batches,\n",
    "        'char_acc': epoch_char_acc / total_batches,\n",
    "        'exact_match_acc': epoch_exact_match_acc / total_batches\n",
    "    }\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    epoch_char_acc = 0\n",
    "    epoch_exact_match_acc = 0\n",
    "    total_batches = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for src, tgt in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            batch_size = src.size(0)\n",
    "            src, tgt = src.to(device), tgt.to(device)\n",
    "            \n",
    "            # Forward pass (use teacher forcing for loss calculation)\n",
    "            output = model(src, tgt)\n",
    "            \n",
    "            # Flatten output and target tensors for loss calculation\n",
    "            output_flat = output.reshape(-1, output.shape[-1])\n",
    "            target_flat = tgt[:, 1:].reshape(-1)  # Shift right to predict next token\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = criterion(output_flat, target_flat)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            char_acc = compute_char_accuracy(output, tgt[:, 1:])\n",
    "            \n",
    "            # Decode for exact match accuracy (no teacher forcing)\n",
    "            predictions, _ = model.decode(src)\n",
    "            exact_match_acc = compute_exact_match_accuracy(predictions, tgt, dataloader.dataset.tgt_vocab)\n",
    "            \n",
    "            # Count exact matches for reporting\n",
    "            correct_batch = int(exact_match_acc * batch_size)\n",
    "            correct_predictions += correct_batch\n",
    "            total_predictions += batch_size\n",
    "            \n",
    "            # Accumulate metrics\n",
    "            epoch_loss += loss.item() * batch_size\n",
    "            epoch_char_acc += char_acc * batch_size\n",
    "            epoch_exact_match_acc += exact_match_acc * batch_size\n",
    "            total_batches += batch_size\n",
    "    \n",
    "    # Return average metrics\n",
    "    return {\n",
    "        'loss': epoch_loss / total_batches,\n",
    "        'char_acc': epoch_char_acc / total_batches,\n",
    "        'exact_match_acc': epoch_exact_match_acc / total_batches,\n",
    "        'correct': correct_predictions,\n",
    "        'total': total_predictions\n",
    "    }\n",
    "\n",
    "# ---- WandB Sweep Configuration ----\n",
    "sweep_config = {\n",
    "    \"name\": \"Seq2Seq\",\n",
    "    \"method\": \"bayes\",\n",
    "    'metric': {\n",
    "        'name': 'validation_accuracy',\n",
    "        'goal': 'maximize'\n",
    "    },\n",
    "    'parameters': {\n",
    "        'cell_type': {\n",
    "            'values': ['lstm', 'gru', 'rnn']\n",
    "        },\n",
    "        'dropout': {\n",
    "            'values': [0, 0.1, 0.2, 0.5]\n",
    "        },\n",
    "        'embedding_size': {\n",
    "            'values': [64, 128, 256, 512]\n",
    "        },\n",
    "        'num_layers': {\n",
    "            'values': [2, 3, 4]\n",
    "        },\n",
    "        'batch_size': {\n",
    "            'values': [32, 64, 128]\n",
    "        },\n",
    "        'hidden_size': {\n",
    "            'values': [128, 256, 512]\n",
    "        },\n",
    "        'bidirectional': {\n",
    "            'values': [True, False]\n",
    "        },\n",
    "        'learning_rate': {\n",
    "            \"values\": [0.001, 0.002, 0.0001, 0.0002]\n",
    "        },\n",
    "        'epochs': {\n",
    "            'values': [15]\n",
    "        },\n",
    "        'optim': {\n",
    "            \"values\": ['adam']\n",
    "        },\n",
    "        'teacher_forcing': {\n",
    "            \"values\": [0.2, 0.5, 0.7]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# ---- WandB Sweep Function ----\n",
    "def sweep_run():\n",
    "    # Initialize WandB run\n",
    "    run = wandb.init()\n",
    "    \n",
    "    # Get hyperparameters from sweep\n",
    "    config = wandb.config\n",
    "    \n",
    "    # Create run name\n",
    "    run_name = f\"{config.cell_type}-e{config.embedding_size}-h{config.hidden_size}-n{config.num_layers}-d{config.dropout}-b{config.bidirectional}-tf{config.teacher_forcing}-lr{config.learning_rate}-bs{config.batch_size}-{config.optim}\"\n",
    "    wandb.run.name = run_name\n",
    "    \n",
    "    # Setup device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Data paths\n",
    "    train_tsv = '/kaggle/input/dakshina-dataset/dakshina_dataset_v1.0/te/lexicons/te.translit.sampled.train.tsv'\n",
    "    dev_tsv = '/kaggle/input/dakshina-dataset/dakshina_dataset_v1.0/te/lexicons/te.translit.sampled.dev.tsv'\n",
    "    test_tsv = '/kaggle/input/dakshina-dataset/dakshina_dataset_v1.0/te/lexicons/te.translit.sampled.test.tsv'\n",
    "    vocab_dir = '/kaggle/working/vocab'\n",
    "    model_dir = '/kaggle/working/models'\n",
    "    \n",
    "    # Create directories\n",
    "    os.makedirs(vocab_dir, exist_ok=True)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    \n",
    "    # Load or build vocabulary\n",
    "    vocab_file = os.path.join(vocab_dir, 'src_vocab.json')\n",
    "    if os.path.exists(vocab_file):\n",
    "        with open(os.path.join(vocab_dir, 'src_vocab.json'), 'r') as f:\n",
    "            src_vocab = json.load(f)\n",
    "        with open(os.path.join(vocab_dir, 'tgt_vocab.json'), 'r') as f:\n",
    "            tgt_vocab = json.load(f)\n",
    "        print(\"Loaded existing vocabulary\")\n",
    "    else:\n",
    "        print(\"Building new vocabulary\")\n",
    "        train_dataset = DakshinaTSVDataset(train_tsv, build_vocab=True)\n",
    "        src_vocab, tgt_vocab = train_dataset.src_vocab, train_dataset.tgt_vocab\n",
    "        \n",
    "        # Save vocabulary\n",
    "        with open(os.path.join(vocab_dir, 'src_vocab.json'), 'w', encoding='utf-8') as f:\n",
    "            json.dump(src_vocab, f, ensure_ascii=False)\n",
    "        with open(os.path.join(vocab_dir, 'tgt_vocab.json'), 'w', encoding='utf-8') as f:\n",
    "            json.dump(tgt_vocab, f, ensure_ascii=False)\n",
    "        print(\"Saved vocabulary\")\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = DakshinaTSVDataset(train_tsv, src_vocab, tgt_vocab)\n",
    "    val_dataset = DakshinaTSVDataset(dev_tsv, src_vocab, tgt_vocab)\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config.batch_size)\n",
    "    \n",
    "    # Create model components\n",
    "    encoder = Encoder(\n",
    "        input_size=len(src_vocab),\n",
    "        embedding_size=config.embedding_size,\n",
    "        hidden_size=config.hidden_size,\n",
    "        num_layers=config.num_layers,\n",
    "        dropout=config.dropout,\n",
    "        bidirectional=config.bidirectional,\n",
    "        cell_type=config.cell_type\n",
    "    )\n",
    "    \n",
    "    # Calculate encoder output size (doubled if bidirectional)\n",
    "    enc_hidden_size = config.hidden_size * 2 if config.bidirectional else config.hidden_size\n",
    "    \n",
    "    decoder = Decoder(\n",
    "        output_size=len(tgt_vocab),\n",
    "        embedding_size=config.embedding_size,\n",
    "        enc_hidden_size=enc_hidden_size,\n",
    "        dec_hidden_size=config.hidden_size,\n",
    "        num_layers=config.num_layers,\n",
    "        dropout=config.dropout,\n",
    "        cell_type=config.cell_type\n",
    "    )\n",
    "    \n",
    "    # Create full model\n",
    "    model = Seq2Seq(encoder, decoder, device, teacher_forcing_ratio=config.teacher_forcing)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Print model size\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Model has {total_params:,} parameters ({trainable_params:,} trainable)\")\n",
    "    \n",
    "    # Loss function (ignore padding token)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "    \n",
    "    # Optimizer\n",
    "    if config.optim == 'nadam':\n",
    "        try:\n",
    "            optimizer = optim.NAdam(model.parameters(), lr=config.learning_rate)\n",
    "        except AttributeError:\n",
    "            print(\"NAdam optimizer not available, falling back to Adam\")\n",
    "            optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "    else:\n",
    "        optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "    \n",
    "    # Training loop\n",
    "    best_val_acc = 0\n",
    "    \n",
    "    for epoch in range(config.epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{config.epochs}\")\n",
    "        \n",
    "        # Train\n",
    "        train_metrics = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        \n",
    "        # Evaluate\n",
    "        val_metrics = evaluate(model, val_loader, criterion, device)\n",
    "        \n",
    "        # Print metrics\n",
    "        print(f\"Train - Loss: {train_metrics['loss']:.4f}, Char Acc: {train_metrics['char_acc']:.4f}, \"\n",
    "              f\"Exact Match: {train_metrics['exact_match_acc']:.4f}\")\n",
    "        print(f\"Val - Loss: {val_metrics['loss']:.4f}, Char Acc: {val_metrics['char_acc']:.4f}, \"\n",
    "              f\"Exact Match: {val_metrics['exact_match_acc']:.4f} ({val_metrics['correct']}/{val_metrics['total']})\")\n",
    "        \n",
    "        # Convert exact match to percentage for wandb\n",
    "        val_accuracy_percent = val_metrics['exact_match_acc'] * 100\n",
    "        \n",
    "        # Log to WandB\n",
    "        wandb.log({\n",
    "            'epoch': epoch + 1,\n",
    "            'train_loss': train_metrics['loss'],\n",
    "            'train_char_accuracy': train_metrics['char_acc'],\n",
    "            'train_exact_match': train_metrics['exact_match_acc'],\n",
    "            'val_loss': val_metrics['loss'],\n",
    "            'val_char_accuracy': val_metrics['char_acc'],\n",
    "            'val_exact_match': val_metrics['exact_match_acc'],\n",
    "            'validation_accuracy': val_accuracy_percent  # This matches the metric name in sweep_config\n",
    "        })\n",
    "        \n",
    "        # Save best model\n",
    "        if val_metrics['exact_match_acc'] > best_val_acc:\n",
    "            best_val_acc = val_metrics['exact_match_acc']\n",
    "            \n",
    "            # Save model\n",
    "            model_path = os.path.join(model_dir, f\"{run_name}_best.pt\")\n",
    "            torch.save({\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_loss': val_metrics['loss'],\n",
    "                'val_accuracy': val_metrics['exact_match_acc'],\n",
    "                'config': {k: v for k, v in config.__dict__.items() if not k.startswith('_')}\n",
    "            }, model_path)\n",
    "            \n",
    "            # Create a new artifact for this model\n",
    "            artifact_name = f\"model-{run.id}-epoch{epoch+1}\"\n",
    "            artifact = wandb.Artifact(artifact_name, type=\"model\")\n",
    "            artifact.add_file(model_path)\n",
    "            run.log_artifact(artifact)\n",
    "            \n",
    "            print(f\"Saved new best model with validation accuracy: {best_val_acc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T20:18:42.088950Z",
     "iopub.status.busy": "2025-05-16T20:18:42.088350Z",
     "iopub.status.idle": "2025-05-16T20:23:56.867588Z",
     "shell.execute_reply": "2025-05-16T20:23:56.866839Z",
     "shell.execute_reply.started": "2025-05-16T20:18:42.088923Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ---- Main Function ----\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize a new sweep\n",
    "    sweep_id = wandb.sweep(sweep_config, project=\"dakshina-transliteration\")\n",
    "    \n",
    "    # Start the sweep agent\n",
    "    # You can adjust count to determine how many runs to do\n",
    "    wandb.agent(sweep_id, sweep_run, count=50)  # Run 10 trials\n",
    "    \n",
    "    print(\"Sweep completed!.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# gru-e512-h256-n2-d0.1-bFalse-tf0.7-lr0.002-bs128-adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T15:30:15.495334Z",
     "iopub.status.busy": "2025-05-19T15:30:15.495151Z",
     "iopub.status.idle": "2025-05-19T15:30:15.522211Z",
     "shell.execute_reply": "2025-05-19T15:30:15.521549Z",
     "shell.execute_reply.started": "2025-05-19T15:30:15.495318Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ---- Function to run with best parameters ----\n",
    "def run_best_params():\n",
    "    # Best parameters as provided\n",
    "    params = {\n",
    "        'cell_type': 'gru',\n",
    "        'dropout': 0.1,\n",
    "        'num_layers': 2,\n",
    "        'batch_size': 128,\n",
    "        'hidden_size': 256,\n",
    "        'embedding_size': 512,\n",
    "        'bidirectional': False,\n",
    "        'learning_rate': 0.002,\n",
    "        'epochs': 15,\n",
    "        'optim': 'adam',\n",
    "        'teacher_forcing': 0.7\n",
    "    }\n",
    "    \n",
    "    # Setup device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Data paths\n",
    "    train_tsv = '/kaggle/input/dakshina-dataset/dakshina_dataset_v1.0/te/lexicons/te.translit.sampled.train.tsv'\n",
    "    dev_tsv = '/kaggle/input/dakshina-dataset/dakshina_dataset_v1.0/te/lexicons/te.translit.sampled.dev.tsv'\n",
    "    test_tsv = '/kaggle/input/dakshina-dataset/dakshina_dataset_v1.0/te/lexicons/te.translit.sampled.test.tsv'\n",
    "    vocab_dir = '/kaggle/working/vocab_best'\n",
    "    model_dir = '/kaggle/working/models_best'\n",
    "    \n",
    "    # Create directories\n",
    "    os.makedirs(vocab_dir, exist_ok=True)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    \n",
    "    # Initialize wandb if needed\n",
    "    use_wandb = False  # Set to True if you want to use wandb\n",
    "    if use_wandb:\n",
    "        wandb.init(project=\"dakshina-transliteration\", config=params)\n",
    "    \n",
    "    # Load or build vocabulary\n",
    "    vocab_file = os.path.join(vocab_dir, 'src_vocab.json')\n",
    "    if os.path.exists(vocab_file):\n",
    "        with open(os.path.join(vocab_dir, 'src_vocab.json'), 'r') as f:\n",
    "            src_vocab = json.load(f)\n",
    "        with open(os.path.join(vocab_dir, 'tgt_vocab.json'), 'r') as f:\n",
    "            tgt_vocab = json.load(f)\n",
    "        print(\"Loaded existing vocabulary\")\n",
    "    else:\n",
    "        print(\"Building new vocabulary\")\n",
    "        train_dataset = DakshinaTSVDataset(train_tsv, build_vocab=True)\n",
    "        src_vocab, tgt_vocab = train_dataset.src_vocab, train_dataset.tgt_vocab\n",
    "        \n",
    "        # Save vocabulary\n",
    "        with open(os.path.join(vocab_dir, 'src_vocab.json'), 'w', encoding='utf-8') as f:\n",
    "            json.dump(src_vocab, f, ensure_ascii=False)\n",
    "        with open(os.path.join(vocab_dir, 'tgt_vocab.json'), 'w', encoding='utf-8') as f:\n",
    "            json.dump(tgt_vocab, f, ensure_ascii=False)\n",
    "        print(\"Saved vocabulary\")\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = DakshinaTSVDataset(train_tsv, src_vocab, tgt_vocab)\n",
    "    val_dataset = DakshinaTSVDataset(dev_tsv, src_vocab, tgt_vocab)\n",
    "    test_dataset = DakshinaTSVDataset(test_tsv, src_vocab, tgt_vocab)\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=params['batch_size'], shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=params['batch_size'])\n",
    "    test_loader = DataLoader(test_dataset, batch_size=params['batch_size'])\n",
    "    \n",
    "    print(f\"Loaded datasets - Train: {len(train_dataset)}, Val: {len(val_dataset)}, Test: {len(test_dataset)}\")\n",
    "    \n",
    "    # Create model components\n",
    "    encoder = Encoder(\n",
    "        input_size=len(src_vocab),\n",
    "        embedding_size=params['embedding_size'],\n",
    "        hidden_size=params['hidden_size'],\n",
    "        num_layers=params['num_layers'],\n",
    "        dropout=params['dropout'],\n",
    "        bidirectional=params['bidirectional'],\n",
    "        cell_type=params['cell_type']\n",
    "    )\n",
    "    \n",
    "    # Calculate encoder output size (doubled if bidirectional)\n",
    "    enc_hidden_size = params['hidden_size'] * 2 if params['bidirectional'] else params['hidden_size']\n",
    "    \n",
    "    decoder = Decoder(\n",
    "        output_size=len(tgt_vocab),\n",
    "        embedding_size=params['embedding_size'],\n",
    "        enc_hidden_size=enc_hidden_size,\n",
    "        dec_hidden_size=params['hidden_size'],\n",
    "        num_layers=params['num_layers'],\n",
    "        dropout=params['dropout'],\n",
    "        cell_type=params['cell_type']\n",
    "    )\n",
    "    \n",
    "    # Create full model\n",
    "    model = Seq2Seq(encoder, decoder, device, teacher_forcing_ratio=params['teacher_forcing'])\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Print model size\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Model has {total_params:,} parameters ({trainable_params:,} trainable)\")\n",
    "    \n",
    "    # Loss function (ignore padding token)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "    \n",
    "    # Optimizer\n",
    "    if params['optim'] == 'nadam':\n",
    "        try:\n",
    "            optimizer = optim.NAdam(model.parameters(), lr=params['learning_rate'])\n",
    "        except AttributeError:\n",
    "            print(\"NAdam optimizer not available, falling back to Adam\")\n",
    "            optimizer = optim.Adam(model.parameters(), lr=params['learning_rate'])\n",
    "    else:\n",
    "        optimizer = optim.Adam(model.parameters(), lr=params['learning_rate'])\n",
    "    \n",
    "    # Training loop\n",
    "    best_val_acc = 0\n",
    "    best_epoch = 0\n",
    "    model_path = os.path.join(model_dir, \"best_model.pt\")\n",
    "    \n",
    "    for epoch in range(params['epochs']):\n",
    "        print(f\"\\nEpoch {epoch+1}/{params['epochs']}\")\n",
    "        \n",
    "        # Train\n",
    "        train_metrics = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        \n",
    "        # Evaluate\n",
    "        val_metrics = evaluate(model, val_loader, criterion, device)\n",
    "        \n",
    "        # Print metrics\n",
    "        print(f\"Train - Loss: {train_metrics['loss']:.4f}, Char Acc: {train_metrics['char_acc']:.4f}, \"\n",
    "              f\"Exact Match: {train_metrics['exact_match_acc']:.4f}\")\n",
    "        print(f\"Val - Loss: {val_metrics['loss']:.4f}, Char Acc: {val_metrics['char_acc']:.4f}, \"\n",
    "              f\"Exact Match: {val_metrics['exact_match_acc']:.4f} ({val_metrics['correct']}/{val_metrics['total']})\")\n",
    "        \n",
    "        # Log to WandB\n",
    "        if use_wandb:\n",
    "            wandb.log({\n",
    "                'epoch': epoch + 1,\n",
    "                'train_loss': train_metrics['loss'],\n",
    "                'train_char_accuracy': train_metrics['char_acc'],\n",
    "                'train_exact_match': train_metrics['exact_match_acc'],\n",
    "                'val_loss': val_metrics['loss'],\n",
    "                'val_char_accuracy': val_metrics['char_acc'],\n",
    "                'val_exact_match': val_metrics['exact_match_acc']\n",
    "            })\n",
    "        \n",
    "        # Save best model\n",
    "        if val_metrics['exact_match_acc'] > best_val_acc:\n",
    "            best_val_acc = val_metrics['exact_match_acc']\n",
    "            best_epoch = epoch + 1\n",
    "            \n",
    "            # Save model\n",
    "            torch.save({\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_loss': val_metrics['loss'],\n",
    "                'val_accuracy': val_metrics['exact_match_acc'],\n",
    "                'params': params\n",
    "            }, model_path)\n",
    "            \n",
    "            print(f\"Saved new best model with validation accuracy: {best_val_acc:.4f}\")\n",
    "    \n",
    "    print(f\"\\nTraining complete. Best validation accuracy: {best_val_acc:.4f} at epoch {best_epoch}\")\n",
    "    \n",
    "    # Load best model for testing\n",
    "    print(\"\\nLoading best model for testing...\")\n",
    "    checkpoint = torch.load(model_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    test_metrics = evaluate(model, test_loader, criterion, device)\n",
    "    \n",
    "    print(f\"\\nTest Results:\")\n",
    "    print(f\"Loss: {test_metrics['loss']:.4f}\")\n",
    "    print(f\"Character Accuracy: {test_metrics['char_acc']:.4f}\")\n",
    "    print(f\"Exact Match Accuracy: {test_metrics['exact_match_acc']:.4f} \"\n",
    "          f\"({test_metrics['correct']}/{test_metrics['total']})\")\n",
    "    \n",
    "    # Log final results to WandB\n",
    "    if use_wandb:\n",
    "        wandb.log({\n",
    "            'test_loss': test_metrics['loss'],\n",
    "            'test_char_accuracy': test_metrics['char_acc'],\n",
    "            'test_exact_match': test_metrics['exact_match_acc'],\n",
    "            'best_val_accuracy': best_val_acc\n",
    "        })\n",
    "    \n",
    "    # Display examples of correct and incorrect predictions\n",
    "    print(\"\\nAnalyzing predictions on test set...\")\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    all_sources = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for src, tgt in test_loader:\n",
    "            src, tgt = src.to(device), tgt.to(device)\n",
    "            predictions, _ = model.decode(src)\n",
    "            \n",
    "            # Convert to readable strings\n",
    "            id_to_char = {v: k for k, v in test_dataset.tgt_vocab.items() \n",
    "                         if k not in ['<pad>', '<sos>', '<eos>', '<unk>']}\n",
    "            \n",
    "            for i in range(src.size(0)):\n",
    "                # Source (roman)\n",
    "                src_str = ''.join([test_dataset.src_vocab.get(str(idx.item()), '') \n",
    "                                  for idx in src[i] if idx.item() not in [0, 1, 2, 3]])\n",
    "                \n",
    "                # Target (native)\n",
    "                tgt_str = ''.join([id_to_char.get(idx.item(), '') \n",
    "                                  for idx in tgt[i, 1:] if idx.item() not in [0, 1, 2, 3]])\n",
    "                \n",
    "                # Prediction\n",
    "                pred_str = ''.join([id_to_char.get(idx.item(), '') \n",
    "                                   for idx in predictions[i, 1:] if idx.item() not in [0, 1, 2, 3]])\n",
    "                \n",
    "                all_sources.append(src_str)\n",
    "                all_targets.append(tgt_str)\n",
    "                all_predictions.append(pred_str)\n",
    "    \n",
    "    # Get correct and incorrect examples\n",
    "    correct_examples = [(s, t, p) for s, t, p in zip(all_sources, all_targets, all_predictions) if t == p]\n",
    "    incorrect_examples = [(s, t, p) for s, t, p in zip(all_sources, all_targets, all_predictions) if t != p]\n",
    "    \n",
    "    # Display some correct examples\n",
    "    print(f\"\\nCorrect Examples ({len(correct_examples)} total):\")\n",
    "    for i, (src, tgt, pred) in enumerate(correct_examples[:5]):\n",
    "        print(f\"{i+1}. Roman: '{src}'\")\n",
    "        print(f\"   Native: '{tgt}'\")\n",
    "    \n",
    "    # Display some incorrect examples\n",
    "    print(f\"\\nIncorrect Examples ({len(incorrect_examples)} total):\")\n",
    "    for i, (src, tgt, pred) in enumerate(incorrect_examples[:5]):\n",
    "        print(f\"{i+1}. Roman: '{src}'\")\n",
    "        print(f\"   Native (correct): '{tgt}'\")\n",
    "        print(f\"   Prediction: '{pred}'\")\n",
    "    \n",
    "    return {\n",
    "        'val_accuracy': best_val_acc,\n",
    "        'test_accuracy': test_metrics['exact_match_acc'],\n",
    "        'correct': test_metrics['correct'],\n",
    "        'total': test_metrics['total']\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T15:30:58.085940Z",
     "iopub.status.busy": "2025-05-19T15:30:58.085042Z",
     "iopub.status.idle": "2025-05-19T16:03:42.342646Z",
     "shell.execute_reply": "2025-05-19T16:03:42.342058Z",
     "shell.execute_reply.started": "2025-05-19T15:30:58.085899Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Building new vocabulary\n",
      "Loaded 58550 examples from /kaggle/input/dakshina-dataset/dakshina_dataset_v1.0/te/lexicons/te.translit.sampled.train.tsv\n",
      "Sample examples:\n",
      "  Roman: 'amkita', Native: ''\n",
      "  Roman: 'ankita', Native: ''\n",
      "  Roman: 'ankitha', Native: ''\n",
      "Vocab sizes -> src: 30, tgt: 67\n",
      "Saved vocabulary\n",
      "Loaded 58550 examples from /kaggle/input/dakshina-dataset/dakshina_dataset_v1.0/te/lexicons/te.translit.sampled.train.tsv\n",
      "Sample examples:\n",
      "  Roman: 'amkita', Native: ''\n",
      "  Roman: 'ankita', Native: ''\n",
      "  Roman: 'ankitha', Native: ''\n",
      "Loaded 5683 examples from /kaggle/input/dakshina-dataset/dakshina_dataset_v1.0/te/lexicons/te.translit.sampled.dev.tsv\n",
      "Sample examples:\n",
      "  Roman: 'amka', Native: ''\n",
      "  Roman: 'anka', Native: ''\n",
      "  Roman: 'amkam', Native: ''\n",
      "Loaded 5747 examples from /kaggle/input/dakshina-dataset/dakshina_dataset_v1.0/te/lexicons/te.translit.sampled.test.tsv\n",
      "Sample examples:\n",
      "  Roman: 'amkamlo', Native: ''\n",
      "  Roman: 'ankamlo', Native: ''\n",
      "  Roman: 'ankamloo', Native: ''\n",
      "Loaded datasets - Train: 58550, Val: 5683, Test: 5747\n",
      "Model has 2,418,755 parameters (2,418,755 trainable)\n",
      "\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 458/458 [02:05<00:00,  3.65it/s]\n",
      "Evaluating: 100%|| 45/45 [00:06<00:00,  7.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.7351, Char Acc: 0.8005, Exact Match: 0.3558\n",
      "Val - Loss: 0.4398, Char Acc: 0.8769, Exact Match: 0.4392 (2496/5683)\n",
      "Saved new best model with validation accuracy: 0.4392\n",
      "\n",
      "Epoch 2/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 458/458 [02:02<00:00,  3.73it/s]\n",
      "Evaluating: 100%|| 45/45 [00:06<00:00,  7.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.3903, Char Acc: 0.8963, Exact Match: 0.5273\n",
      "Val - Loss: 0.3757, Char Acc: 0.8952, Exact Match: 0.4788 (2721/5683)\n",
      "Saved new best model with validation accuracy: 0.4788\n",
      "\n",
      "Epoch 3/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 458/458 [02:02<00:00,  3.74it/s]\n",
      "Evaluating: 100%|| 45/45 [00:06<00:00,  7.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.3335, Char Acc: 0.9119, Exact Match: 0.5953\n",
      "Val - Loss: 0.4505, Char Acc: 0.8772, Exact Match: 0.4767 (2709/5683)\n",
      "\n",
      "Epoch 4/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 458/458 [02:02<00:00,  3.75it/s]\n",
      "Evaluating: 100%|| 45/45 [00:06<00:00,  7.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.2941, Char Acc: 0.9224, Exact Match: 0.6007\n",
      "Val - Loss: 0.4068, Char Acc: 0.8922, Exact Match: 0.5147 (2925/5683)\n",
      "Saved new best model with validation accuracy: 0.5147\n",
      "\n",
      "Epoch 5/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 458/458 [02:02<00:00,  3.74it/s]\n",
      "Evaluating: 100%|| 45/45 [00:06<00:00,  7.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.2846, Char Acc: 0.9250, Exact Match: 0.6311\n",
      "Val - Loss: 0.3864, Char Acc: 0.8985, Exact Match: 0.4753 (2701/5683)\n",
      "\n",
      "Epoch 6/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 458/458 [02:02<00:00,  3.74it/s]\n",
      "Evaluating: 100%|| 45/45 [00:06<00:00,  6.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.2517, Char Acc: 0.9337, Exact Match: 0.6358\n",
      "Val - Loss: 0.4362, Char Acc: 0.8837, Exact Match: 0.4742 (2695/5683)\n",
      "\n",
      "Epoch 7/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 458/458 [02:02<00:00,  3.74it/s]\n",
      "Evaluating: 100%|| 45/45 [00:06<00:00,  7.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.2649, Char Acc: 0.9304, Exact Match: 0.6496\n",
      "Val - Loss: 0.4431, Char Acc: 0.8867, Exact Match: 0.5170 (2938/5683)\n",
      "Saved new best model with validation accuracy: 0.5170\n",
      "\n",
      "Epoch 8/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 458/458 [02:02<00:00,  3.74it/s]\n",
      "Evaluating: 100%|| 45/45 [00:06<00:00,  7.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.2599, Char Acc: 0.9322, Exact Match: 0.6409\n",
      "Val - Loss: 0.4238, Char Acc: 0.8870, Exact Match: 0.5061 (2876/5683)\n",
      "\n",
      "Epoch 9/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 458/458 [02:02<00:00,  3.74it/s]\n",
      "Evaluating: 100%|| 45/45 [00:06<00:00,  7.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.2530, Char Acc: 0.9334, Exact Match: 0.6291\n",
      "Val - Loss: 0.4194, Char Acc: 0.8960, Exact Match: 0.5179 (2943/5683)\n",
      "Saved new best model with validation accuracy: 0.5179\n",
      "\n",
      "Epoch 10/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 458/458 [02:02<00:00,  3.74it/s]\n",
      "Evaluating: 100%|| 45/45 [00:06<00:00,  7.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.2951, Char Acc: 0.9241, Exact Match: 0.5785\n",
      "Val - Loss: 0.4505, Char Acc: 0.8881, Exact Match: 0.5098 (2897/5683)\n",
      "\n",
      "Epoch 11/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 458/458 [02:01<00:00,  3.76it/s]\n",
      "Evaluating: 100%|| 45/45 [00:06<00:00,  6.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.2555, Char Acc: 0.9329, Exact Match: 0.6267\n",
      "Val - Loss: 0.4584, Char Acc: 0.8803, Exact Match: 0.4630 (2631/5683)\n",
      "\n",
      "Epoch 12/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 458/458 [02:04<00:00,  3.68it/s]\n",
      "Evaluating: 100%|| 45/45 [00:06<00:00,  7.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.2359, Char Acc: 0.9378, Exact Match: 0.6457\n",
      "Val - Loss: 0.4066, Char Acc: 0.8952, Exact Match: 0.5094 (2895/5683)\n",
      "\n",
      "Epoch 13/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 458/458 [02:04<00:00,  3.67it/s]\n",
      "Evaluating: 100%|| 45/45 [00:06<00:00,  7.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.2397, Char Acc: 0.9368, Exact Match: 0.6254\n",
      "Val - Loss: 0.4044, Char Acc: 0.8949, Exact Match: 0.4496 (2555/5683)\n",
      "\n",
      "Epoch 14/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 458/458 [02:04<00:00,  3.67it/s]\n",
      "Evaluating: 100%|| 45/45 [00:06<00:00,  7.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.2271, Char Acc: 0.9396, Exact Match: 0.6352\n",
      "Val - Loss: 0.4307, Char Acc: 0.8942, Exact Match: 0.4804 (2730/5683)\n",
      "\n",
      "Epoch 15/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 458/458 [02:04<00:00,  3.68it/s]\n",
      "Evaluating: 100%|| 45/45 [00:06<00:00,  6.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.2390, Char Acc: 0.9372, Exact Match: 0.6195\n",
      "Val - Loss: 0.4555, Char Acc: 0.8836, Exact Match: 0.4774 (2713/5683)\n",
      "\n",
      "Training complete. Best validation accuracy: 0.5179 at epoch 9\n",
      "\n",
      "Loading best model for testing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 45/45 [00:06<00:00,  7.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Results:\n",
      "Loss: 0.4370\n",
      "Character Accuracy: 0.8912\n",
      "Exact Match Accuracy: 0.5072 (2915/5747)\n",
      "\n",
      "Analyzing predictions on test set...\n",
      "\n",
      "Correct Examples (2915 total):\n",
      "1. Roman: ''\n",
      "   Native: ''\n",
      "2. Roman: ''\n",
      "   Native: ''\n",
      "3. Roman: ''\n",
      "   Native: ''\n",
      "4. Roman: ''\n",
      "   Native: ''\n",
      "5. Roman: ''\n",
      "   Native: ''\n",
      "\n",
      "Incorrect Examples (2832 total):\n",
      "1. Roman: ''\n",
      "   Native (correct): ''\n",
      "   Prediction: ''\n",
      "2. Roman: ''\n",
      "   Native (correct): ''\n",
      "   Prediction: ''\n",
      "3. Roman: ''\n",
      "   Native (correct): ''\n",
      "   Prediction: ''\n",
      "4. Roman: ''\n",
      "   Native (correct): ''\n",
      "   Prediction: ''\n",
      "5. Roman: ''\n",
      "   Native (correct): ''\n",
      "   Prediction: ''\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_accuracy': 0.5178602850607074,\n",
       " 'test_accuracy': 0.507221158865495,\n",
       " 'correct': 2915,\n",
       " 'total': 5747}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_best_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# rnn-e512-h512-n4-d0.5-bFalse-tf0.7-lr0.0001-bs64-adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T16:14:21.921790Z",
     "iopub.status.busy": "2025-05-19T16:14:21.921267Z",
     "iopub.status.idle": "2025-05-19T16:14:21.944341Z",
     "shell.execute_reply": "2025-05-19T16:14:21.943597Z",
     "shell.execute_reply.started": "2025-05-19T16:14:21.921767Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ---- Function to run with best parameters ----\n",
    "def run_best_params():\n",
    "    # Best parameters as provided\n",
    "    params = {\n",
    "        'cell_type': 'rnn',\n",
    "        'dropout': 0.5,\n",
    "        'num_layers': 4,\n",
    "        'batch_size': 64,\n",
    "        'hidden_size': 512,\n",
    "        'embedding_size': 512,\n",
    "        'bidirectional': False,\n",
    "        'learning_rate': 0.0001,\n",
    "        'epochs': 15,\n",
    "        'optim': 'adam',\n",
    "        'teacher_forcing': 0.7\n",
    "    }\n",
    "    \n",
    "    # Setup device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Data paths\n",
    "    train_tsv = '/kaggle/input/dakshina-dataset/dakshina_dataset_v1.0/te/lexicons/te.translit.sampled.train.tsv'\n",
    "    dev_tsv = '/kaggle/input/dakshina-dataset/dakshina_dataset_v1.0/te/lexicons/te.translit.sampled.dev.tsv'\n",
    "    test_tsv = '/kaggle/input/dakshina-dataset/dakshina_dataset_v1.0/te/lexicons/te.translit.sampled.test.tsv'\n",
    "    vocab_dir = '/kaggle/working/vocab_best'\n",
    "    model_dir = '/kaggle/working/models_best'\n",
    "    \n",
    "    # Create directories\n",
    "    os.makedirs(vocab_dir, exist_ok=True)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    \n",
    "    # Initialize wandb if needed\n",
    "    use_wandb = False  # Set to True if you want to use wandb\n",
    "    if use_wandb:\n",
    "        wandb.init(project=\"dakshina-transliteration\", config=params)\n",
    "    \n",
    "    # Load or build vocabulary\n",
    "    vocab_file = os.path.join(vocab_dir, 'src_vocab.json')\n",
    "    if os.path.exists(vocab_file):\n",
    "        with open(os.path.join(vocab_dir, 'src_vocab.json'), 'r') as f:\n",
    "            src_vocab = json.load(f)\n",
    "        with open(os.path.join(vocab_dir, 'tgt_vocab.json'), 'r') as f:\n",
    "            tgt_vocab = json.load(f)\n",
    "        print(\"Loaded existing vocabulary\")\n",
    "    else:\n",
    "        print(\"Building new vocabulary\")\n",
    "        train_dataset = DakshinaTSVDataset(train_tsv, build_vocab=True)\n",
    "        src_vocab, tgt_vocab = train_dataset.src_vocab, train_dataset.tgt_vocab\n",
    "        \n",
    "        # Save vocabulary\n",
    "        with open(os.path.join(vocab_dir, 'src_vocab.json'), 'w', encoding='utf-8') as f:\n",
    "            json.dump(src_vocab, f, ensure_ascii=False)\n",
    "        with open(os.path.join(vocab_dir, 'tgt_vocab.json'), 'w', encoding='utf-8') as f:\n",
    "            json.dump(tgt_vocab, f, ensure_ascii=False)\n",
    "        print(\"Saved vocabulary\")\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = DakshinaTSVDataset(train_tsv, src_vocab, tgt_vocab)\n",
    "    val_dataset = DakshinaTSVDataset(dev_tsv, src_vocab, tgt_vocab)\n",
    "    test_dataset = DakshinaTSVDataset(test_tsv, src_vocab, tgt_vocab)\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=params['batch_size'], shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=params['batch_size'])\n",
    "    test_loader = DataLoader(test_dataset, batch_size=params['batch_size'])\n",
    "    \n",
    "    print(f\"Loaded datasets - Train: {len(train_dataset)}, Val: {len(val_dataset)}, Test: {len(test_dataset)}\")\n",
    "    \n",
    "    # Create model components\n",
    "    encoder = Encoder(\n",
    "        input_size=len(src_vocab),\n",
    "        embedding_size=params['embedding_size'],\n",
    "        hidden_size=params['hidden_size'],\n",
    "        num_layers=params['num_layers'],\n",
    "        dropout=params['dropout'],\n",
    "        bidirectional=params['bidirectional'],\n",
    "        cell_type=params['cell_type']\n",
    "    )\n",
    "    \n",
    "    # Calculate encoder output size (doubled if bidirectional)\n",
    "    enc_hidden_size = params['hidden_size'] * 2 if params['bidirectional'] else params['hidden_size']\n",
    "    \n",
    "    decoder = Decoder(\n",
    "        output_size=len(tgt_vocab),\n",
    "        embedding_size=params['embedding_size'],\n",
    "        enc_hidden_size=enc_hidden_size,\n",
    "        dec_hidden_size=params['hidden_size'],\n",
    "        num_layers=params['num_layers'],\n",
    "        dropout=params['dropout'],\n",
    "        cell_type=params['cell_type']\n",
    "    )\n",
    "    \n",
    "    # Create full model\n",
    "    model = Seq2Seq(encoder, decoder, device, teacher_forcing_ratio=params['teacher_forcing'])\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Print model size\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Model has {total_params:,} parameters ({trainable_params:,} trainable)\")\n",
    "    \n",
    "    # Loss function (ignore padding token)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "    \n",
    "    # Optimizer\n",
    "    if params['optim'] == 'nadam':\n",
    "        try:\n",
    "            optimizer = optim.NAdam(model.parameters(), lr=params['learning_rate'])\n",
    "        except AttributeError:\n",
    "            print(\"NAdam optimizer not available, falling back to Adam\")\n",
    "            optimizer = optim.Adam(model.parameters(), lr=params['learning_rate'])\n",
    "    else:\n",
    "        optimizer = optim.Adam(model.parameters(), lr=params['learning_rate'])\n",
    "    \n",
    "    # Training loop\n",
    "    best_val_acc = 0\n",
    "    best_epoch = 0\n",
    "    model_path = os.path.join(model_dir, \"best_model.pt\")\n",
    "    \n",
    "    for epoch in range(params['epochs']):\n",
    "        print(f\"\\nEpoch {epoch+1}/{params['epochs']}\")\n",
    "        \n",
    "        # Train\n",
    "        train_metrics = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        \n",
    "        # Evaluate\n",
    "        val_metrics = evaluate(model, val_loader, criterion, device)\n",
    "        \n",
    "        # Print metrics\n",
    "        print(f\"Train - Loss: {train_metrics['loss']:.4f}, Char Acc: {train_metrics['char_acc']:.4f}, \"\n",
    "              f\"Exact Match: {train_metrics['exact_match_acc']:.4f}\")\n",
    "        print(f\"Val - Loss: {val_metrics['loss']:.4f}, Char Acc: {val_metrics['char_acc']:.4f}, \"\n",
    "              f\"Exact Match: {val_metrics['exact_match_acc']:.4f} ({val_metrics['correct']}/{val_metrics['total']})\")\n",
    "        \n",
    "        # Log to WandB\n",
    "        if use_wandb:\n",
    "            wandb.log({\n",
    "                'epoch': epoch + 1,\n",
    "                'train_loss': train_metrics['loss'],\n",
    "                'train_char_accuracy': train_metrics['char_acc'],\n",
    "                'train_exact_match': train_metrics['exact_match_acc'],\n",
    "                'val_loss': val_metrics['loss'],\n",
    "                'val_char_accuracy': val_metrics['char_acc'],\n",
    "                'val_exact_match': val_metrics['exact_match_acc']\n",
    "            })\n",
    "        \n",
    "        # Save best model\n",
    "        if val_metrics['exact_match_acc'] > best_val_acc:\n",
    "            best_val_acc = val_metrics['exact_match_acc']\n",
    "            best_epoch = epoch + 1\n",
    "            \n",
    "            # Save model\n",
    "            torch.save({\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_loss': val_metrics['loss'],\n",
    "                'val_accuracy': val_metrics['exact_match_acc'],\n",
    "                'params': params\n",
    "            }, model_path)\n",
    "            \n",
    "            print(f\"Saved new best model with validation accuracy: {best_val_acc:.4f}\")\n",
    "    \n",
    "    print(f\"\\nTraining complete. Best validation accuracy: {best_val_acc:.4f} at epoch {best_epoch}\")\n",
    "    \n",
    "    # Load best model for testing\n",
    "    print(\"\\nLoading best model for testing...\")\n",
    "    checkpoint = torch.load(model_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    test_metrics = evaluate(model, test_loader, criterion, device)\n",
    "    \n",
    "    print(f\"\\nTest Results:\")\n",
    "    print(f\"Loss: {test_metrics['loss']:.4f}\")\n",
    "    print(f\"Character Accuracy: {test_metrics['char_acc']:.4f}\")\n",
    "    print(f\"Exact Match Accuracy: {test_metrics['exact_match_acc']:.4f} \"\n",
    "          f\"({test_metrics['correct']}/{test_metrics['total']})\")\n",
    "    \n",
    "    # Log final results to WandB\n",
    "    if use_wandb:\n",
    "        wandb.log({\n",
    "            'test_loss': test_metrics['loss'],\n",
    "            'test_char_accuracy': test_metrics['char_acc'],\n",
    "            'test_exact_match': test_metrics['exact_match_acc'],\n",
    "            'best_val_accuracy': best_val_acc\n",
    "        })\n",
    "    \n",
    "    # Display examples of correct and incorrect predictions\n",
    "    print(\"\\nAnalyzing predictions on test set...\")\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    all_sources = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for src, tgt in test_loader:\n",
    "            src, tgt = src.to(device), tgt.to(device)\n",
    "            predictions, _ = model.decode(src)\n",
    "            \n",
    "            # Convert to readable strings\n",
    "            id_to_char = {v: k for k, v in test_dataset.tgt_vocab.items() \n",
    "                         if k not in ['<pad>', '<sos>', '<eos>', '<unk>']}\n",
    "            \n",
    "            for i in range(src.size(0)):\n",
    "                # Source (roman)\n",
    "                src_str = ''.join([test_dataset.src_vocab.get(str(idx.item()), '') \n",
    "                                  for idx in src[i] if idx.item() not in [0, 1, 2, 3]])\n",
    "                \n",
    "                # Target (native)\n",
    "                tgt_str = ''.join([id_to_char.get(idx.item(), '') \n",
    "                                  for idx in tgt[i, 1:] if idx.item() not in [0, 1, 2, 3]])\n",
    "                \n",
    "                # Prediction\n",
    "                pred_str = ''.join([id_to_char.get(idx.item(), '') \n",
    "                                   for idx in predictions[i, 1:] if idx.item() not in [0, 1, 2, 3]])\n",
    "                \n",
    "                all_sources.append(src_str)\n",
    "                all_targets.append(tgt_str)\n",
    "                all_predictions.append(pred_str)\n",
    "    \n",
    "    # Get correct and incorrect examples\n",
    "    correct_examples = [(s, t, p) for s, t, p in zip(all_sources, all_targets, all_predictions) if t == p]\n",
    "    incorrect_examples = [(s, t, p) for s, t, p in zip(all_sources, all_targets, all_predictions) if t != p]\n",
    "    \n",
    "    # Display some correct examples\n",
    "    print(f\"\\nCorrect Examples ({len(correct_examples)} total):\")\n",
    "    for i, (src, tgt, pred) in enumerate(correct_examples[:5]):\n",
    "        print(f\"{i+1}. Roman: '{src}'\")\n",
    "        print(f\"   Native: '{tgt}'\")\n",
    "    \n",
    "    # Display some incorrect examples\n",
    "    print(f\"\\nIncorrect Examples ({len(incorrect_examples)} total):\")\n",
    "    for i, (src, tgt, pred) in enumerate(incorrect_examples[:5]):\n",
    "        print(f\"{i+1}. Roman: '{src}'\")\n",
    "        print(f\"   Native (correct): '{tgt}'\")\n",
    "        print(f\"   Prediction: '{pred}'\")\n",
    "    \n",
    "    return {\n",
    "        'val_accuracy': best_val_acc,\n",
    "        'test_accuracy': test_metrics['exact_match_acc'],\n",
    "        'correct': test_metrics['correct'],\n",
    "        'total': test_metrics['total']\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T16:14:24.735039Z",
     "iopub.status.busy": "2025-05-19T16:14:24.734561Z",
     "iopub.status.idle": "2025-05-19T17:41:19.719908Z",
     "shell.execute_reply": "2025-05-19T17:41:19.719079Z",
     "shell.execute_reply.started": "2025-05-19T16:14:24.735013Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loaded existing vocabulary\n",
      "Loaded 58550 examples from /kaggle/input/dakshina-dataset/dakshina_dataset_v1.0/te/lexicons/te.translit.sampled.train.tsv\n",
      "Sample examples:\n",
      "  Roman: 'amkita', Native: ''\n",
      "  Roman: 'ankita', Native: ''\n",
      "  Roman: 'ankitha', Native: ''\n",
      "Loaded 5683 examples from /kaggle/input/dakshina-dataset/dakshina_dataset_v1.0/te/lexicons/te.translit.sampled.dev.tsv\n",
      "Sample examples:\n",
      "  Roman: 'amka', Native: ''\n",
      "  Roman: 'anka', Native: ''\n",
      "  Roman: 'amkam', Native: ''\n",
      "Loaded 5747 examples from /kaggle/input/dakshina-dataset/dakshina_dataset_v1.0/te/lexicons/te.translit.sampled.test.tsv\n",
      "Sample examples:\n",
      "  Roman: 'amkamlo', Native: ''\n",
      "  Roman: 'ankamlo', Native: ''\n",
      "  Roman: 'ankamloo', Native: ''\n",
      "Loaded datasets - Train: 58550, Val: 5683, Test: 5747\n",
      "Model has 5,142,595 parameters (5,142,595 trainable)\n",
      "\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 915/915 [05:32<00:00,  2.75it/s]\n",
      "Evaluating: 100%|| 89/89 [00:14<00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 1.7257, Char Acc: 0.5244, Exact Match: 0.0500\n",
      "Val - Loss: 0.7365, Char Acc: 0.7911, Exact Match: 0.2467 (1402/5683)\n",
      "Saved new best model with validation accuracy: 0.2467\n",
      "\n",
      "Epoch 2/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 915/915 [05:33<00:00,  2.74it/s]\n",
      "Evaluating: 100%|| 89/89 [00:14<00:00,  6.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.8121, Char Acc: 0.7763, Exact Match: 0.2127\n",
      "Val - Loss: 0.5601, Char Acc: 0.8433, Exact Match: 0.3648 (2073/5683)\n",
      "Saved new best model with validation accuracy: 0.3648\n",
      "\n",
      "Epoch 3/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 915/915 [05:27<00:00,  2.80it/s]\n",
      "Evaluating: 100%|| 89/89 [00:13<00:00,  6.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.6301, Char Acc: 0.8288, Exact Match: 0.2997\n",
      "Val - Loss: 0.5599, Char Acc: 0.8537, Exact Match: 0.4086 (2322/5683)\n",
      "Saved new best model with validation accuracy: 0.4086\n",
      "\n",
      "Epoch 4/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 915/915 [05:25<00:00,  2.81it/s]\n",
      "Evaluating: 100%|| 89/89 [00:14<00:00,  6.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.5675, Char Acc: 0.8474, Exact Match: 0.3513\n",
      "Val - Loss: 0.4673, Char Acc: 0.8710, Exact Match: 0.4373 (2485/5683)\n",
      "Saved new best model with validation accuracy: 0.4373\n",
      "\n",
      "Epoch 5/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 915/915 [05:31<00:00,  2.76it/s]\n",
      "Evaluating: 100%|| 89/89 [00:14<00:00,  6.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.5157, Char Acc: 0.8611, Exact Match: 0.3884\n",
      "Val - Loss: 0.4846, Char Acc: 0.8731, Exact Match: 0.4765 (2708/5683)\n",
      "Saved new best model with validation accuracy: 0.4765\n",
      "\n",
      "Epoch 6/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 915/915 [05:32<00:00,  2.75it/s]\n",
      "Evaluating: 100%|| 89/89 [00:13<00:00,  6.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.4792, Char Acc: 0.8714, Exact Match: 0.4212\n",
      "Val - Loss: 0.4621, Char Acc: 0.8739, Exact Match: 0.4746 (2697/5683)\n",
      "\n",
      "Epoch 7/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 915/915 [05:33<00:00,  2.75it/s]\n",
      "Evaluating: 100%|| 89/89 [00:14<00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.4471, Char Acc: 0.8800, Exact Match: 0.4388\n",
      "Val - Loss: 0.4388, Char Acc: 0.8815, Exact Match: 0.4918 (2795/5683)\n",
      "Saved new best model with validation accuracy: 0.4918\n",
      "\n",
      "Epoch 8/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 915/915 [05:32<00:00,  2.75it/s]\n",
      "Evaluating: 100%|| 89/89 [00:14<00:00,  6.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.4241, Char Acc: 0.8860, Exact Match: 0.4623\n",
      "Val - Loss: 0.4341, Char Acc: 0.8848, Exact Match: 0.4872 (2769/5683)\n",
      "\n",
      "Epoch 9/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 915/915 [05:32<00:00,  2.75it/s]\n",
      "Evaluating: 100%|| 89/89 [00:14<00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.4017, Char Acc: 0.8919, Exact Match: 0.4806\n",
      "Val - Loss: 0.4071, Char Acc: 0.8895, Exact Match: 0.5131 (2916/5683)\n",
      "Saved new best model with validation accuracy: 0.5131\n",
      "\n",
      "Epoch 10/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 915/915 [05:33<00:00,  2.75it/s]\n",
      "Evaluating: 100%|| 89/89 [00:14<00:00,  6.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.3847, Char Acc: 0.8960, Exact Match: 0.4912\n",
      "Val - Loss: 0.4126, Char Acc: 0.8921, Exact Match: 0.5106 (2902/5683)\n",
      "\n",
      "Epoch 11/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 915/915 [05:30<00:00,  2.77it/s]\n",
      "Evaluating: 100%|| 89/89 [00:13<00:00,  6.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.3823, Char Acc: 0.8977, Exact Match: 0.5063\n",
      "Val - Loss: 0.3798, Char Acc: 0.8978, Exact Match: 0.5286 (3004/5683)\n",
      "Saved new best model with validation accuracy: 0.5286\n",
      "\n",
      "Epoch 12/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 915/915 [05:29<00:00,  2.78it/s]\n",
      "Evaluating: 100%|| 89/89 [00:14<00:00,  6.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.3596, Char Acc: 0.9036, Exact Match: 0.5179\n",
      "Val - Loss: 0.4191, Char Acc: 0.8920, Exact Match: 0.5465 (3106/5683)\n",
      "Saved new best model with validation accuracy: 0.5465\n",
      "\n",
      "Epoch 13/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 915/915 [05:33<00:00,  2.74it/s]\n",
      "Evaluating: 100%|| 89/89 [00:14<00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.3474, Char Acc: 0.9061, Exact Match: 0.5309\n",
      "Val - Loss: 0.4164, Char Acc: 0.8925, Exact Match: 0.5367 (3050/5683)\n",
      "\n",
      "Epoch 14/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 915/915 [05:33<00:00,  2.75it/s]\n",
      "Evaluating: 100%|| 89/89 [00:13<00:00,  6.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.3343, Char Acc: 0.9099, Exact Match: 0.5408\n",
      "Val - Loss: 0.3845, Char Acc: 0.8987, Exact Match: 0.5453 (3099/5683)\n",
      "\n",
      "Epoch 15/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 915/915 [05:32<00:00,  2.75it/s]\n",
      "Evaluating: 100%|| 89/89 [00:14<00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.3284, Char Acc: 0.9113, Exact Match: 0.5531\n",
      "Val - Loss: 0.3450, Char Acc: 0.9066, Exact Match: 0.5437 (3090/5683)\n",
      "\n",
      "Training complete. Best validation accuracy: 0.5465 at epoch 12\n",
      "\n",
      "Loading best model for testing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 90/90 [00:14<00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Results:\n",
      "Loss: 0.3768\n",
      "Character Accuracy: 0.8969\n",
      "Exact Match Accuracy: 0.5333 (3065/5747)\n",
      "\n",
      "Analyzing predictions on test set...\n",
      "\n",
      "Correct Examples (3065 total):\n",
      "1. Roman: ''\n",
      "   Native: ''\n",
      "2. Roman: ''\n",
      "   Native: ''\n",
      "3. Roman: ''\n",
      "   Native: ''\n",
      "4. Roman: ''\n",
      "   Native: ''\n",
      "5. Roman: ''\n",
      "   Native: ''\n",
      "\n",
      "Incorrect Examples (2682 total):\n",
      "1. Roman: ''\n",
      "   Native (correct): ''\n",
      "   Prediction: ''\n",
      "2. Roman: ''\n",
      "   Native (correct): ''\n",
      "   Prediction: ''\n",
      "3. Roman: ''\n",
      "   Native (correct): ''\n",
      "   Prediction: ''\n",
      "4. Roman: ''\n",
      "   Native (correct): ''\n",
      "   Prediction: ''\n",
      "5. Roman: ''\n",
      "   Native (correct): ''\n",
      "   Prediction: ''\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_accuracy': 0.5465423191976069,\n",
       " 'test_accuracy': 0.5333217330781277,\n",
       " 'correct': 3065,\n",
       " 'total': 5747}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_best_params()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7433379,
     "sourceId": 11832252,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
